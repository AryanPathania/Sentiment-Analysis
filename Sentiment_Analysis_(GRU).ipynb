{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOm-SaY15O_c"
      },
      "source": [
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sk4stdv6kUR",
        "outputId": "a4e70aef-033a-4f03-c7de-af36e2cdaf4e"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oBT7FhD7kjU"
      },
      "source": [
        "train = pd.read_csv(\"/content/Train.csv\")\r\n",
        "valid = pd.read_csv(\"/content/Valid.csv\")\r\n",
        "test = pd.read_csv(\"/content/Test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8TMYgUlvG0L"
      },
      "source": [
        "dataset = pd.concat([train, valid, test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmBfz30DvP7b",
        "outputId": "65001036-ce57-450a-8222-a4758ebe2d7c"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGE5ee9n8aZr"
      },
      "source": [
        "Process the Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stW4fMDf8YiU"
      },
      "source": [
        "class Sequences(Dataset):\r\n",
        "    def __init__(self, data, max_seq_len):\r\n",
        "        self.max_seq_len = max_seq_len\r\n",
        "        df = data\r\n",
        "        vectorizer = CountVectorizer(stop_words='english', min_df=0.015)\r\n",
        "        vectorizer.fit(df.text.tolist())\r\n",
        "        \r\n",
        "        self.token2idx = vectorizer.vocabulary_\r\n",
        "        self.token2idx['<PAD>'] = max(self.token2idx.values()) + 1\r\n",
        "\r\n",
        "        tokenizer = vectorizer.build_analyzer()\r\n",
        "        self.encode = lambda x: [self.token2idx[token] for token in tokenizer(x)\r\n",
        "                                 if token in self.token2idx]\r\n",
        "        self.pad = lambda x: x + (max_seq_len - len(x)) * [self.token2idx['<PAD>']]\r\n",
        "        \r\n",
        "        sequences = [self.encode(sequence)[:max_seq_len] for sequence in df.text.tolist()]\r\n",
        "        sequences, self.labels = zip(*[(sequence, label) for sequence, label\r\n",
        "                                    in zip(sequences, df.label.tolist()) if sequence])\r\n",
        "        self.sequences = [self.pad(sequence) for sequence in sequences]\r\n",
        "\r\n",
        "    def __getitem__(self, i):\r\n",
        "        assert len(self.sequences[i]) == self.max_seq_len\r\n",
        "        return self.sequences[i], self.labels[i]\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.sequences)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnsEhxSvCnXt"
      },
      "source": [
        "data = Sequences(dataset, max_seq_len=240)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enjYwZ1Kf6Sr",
        "outputId": "bbacd4c6-556c-4e8f-c046-8944ac13b072"
      },
      "source": [
        "len(data.token2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1046"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51IQeHwvwMdd"
      },
      "source": [
        "def collate(batch):\r\n",
        "    inputs = torch.LongTensor([item[0] for item in batch])\r\n",
        "    target = torch.FloatTensor([item[1] for item in batch])\r\n",
        "    return inputs, target\r\n",
        "\r\n",
        "batch_size = 2048\r\n",
        "train_loader = DataLoader(data, batch_size=batch_size, collate_fn=collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB46jrRPjqXd"
      },
      "source": [
        "class Model(nn.Module):\r\n",
        "    def __init__(self,\r\n",
        "                 vocab_size, batch_size,\r\n",
        "                 embedding_dimension = 100,\r\n",
        "                 hidden_size = 240, n_layers = 1,\r\n",
        "                 device = \"cpu\"):\r\n",
        "        super(Model, self).__init__()\r\n",
        "        self.n_layers = n_layers\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.device = device\r\n",
        "        self.batch_size = batch_size\r\n",
        "\r\n",
        "        self.encoder = nn.Embedding(vocab_size, embedding_dimension)\r\n",
        "        self.rnn = nn.GRU(\r\n",
        "            embedding_dimension, hidden_size,\r\n",
        "            num_layers = n_layers,\r\n",
        "            batch_first = True\r\n",
        "        )\r\n",
        "        self.decoder = nn.Linear(hidden_size, 1)\r\n",
        "\r\n",
        "    def init_hidden(self):\r\n",
        "        return torch.rand(self.n_layers, self.batch_size, self.hidden_size).to(self.device)\r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        # Avoid breaking if the last batch has a different size\r\n",
        "        batch_size = inputs.size(0)\r\n",
        "        if batch_size != self.batch_size:\r\n",
        "            self.batch_size = batch_size\r\n",
        "\r\n",
        "        encoded = self.encoder(inputs)\r\n",
        "        output, hidden = self.rnn(encoded, self.init_hidden())\r\n",
        "        output = self.decoder(output[:,:,-1]).squeeze()\r\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FsZlE2johZt",
        "outputId": "48cdbadd-b869-47b7-bea2-053ab40e4f07"
      },
      "source": [
        "net = Model(hidden_size=240,\r\n",
        "            vocab_size = len(data.token2idx),\r\n",
        "            device = device,\r\n",
        "            batch_size = batch_size)\r\n",
        "\r\n",
        "net = net.to(device)\r\n",
        "net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): Embedding(1046, 100)\n",
              "  (rnn): GRU(100, 240, batch_first=True)\n",
              "  (decoder): Linear(in_features=240, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qchChE15wAT8"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\r\n",
        "optimizer = optim.Adam([p for p in net.parameters() if p.requires_grad], lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZjNtVfAdbNK",
        "outputId": "97f12267-37fc-421f-9ed5-ac269b0f1862"
      },
      "source": [
        "net.train()\r\n",
        "train_losses = []\r\n",
        "for epoch in range(1,11):\r\n",
        "    losses = []\r\n",
        "    total = 0\r\n",
        "    for inputs, target in train_loader:\r\n",
        "        inputs, target = inputs.to(device), target.to(device)\r\n",
        "\r\n",
        "        net.zero_grad()\r\n",
        "        output = net(inputs)\r\n",
        "        loss = criterion(output, target)\r\n",
        "        loss.backward()\r\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 3)\r\n",
        "        optimizer.step()\r\n",
        "        losses.append(loss.item())\r\n",
        "        total += 1\r\n",
        "    \r\n",
        "    epoch_loss = sum(losses)/total\r\n",
        "    train_losses.append(epoch_loss)\r\n",
        "\r\n",
        "    print(f\"Epoch {epoch}\\t Train Loss:{epoch_loss:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\t Train Loss:0.666\n",
            "Epoch 2\t Train Loss:0.521\n",
            "Epoch 3\t Train Loss:0.433\n",
            "Epoch 4\t Train Loss:0.367\n",
            "Epoch 5\t Train Loss:0.330\n",
            "Epoch 6\t Train Loss:0.309\n",
            "Epoch 7\t Train Loss:0.294\n",
            "Epoch 8\t Train Loss:0.283\n",
            "Epoch 9\t Train Loss:0.272\n",
            "Epoch 10\t Train Loss:0.262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtVdffaIhOds"
      },
      "source": [
        "def predict_sentiment(text):\r\n",
        "    net.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        test_vector = torch.LongTensor([data.pad(data.encode(text))]).to(device)\r\n",
        "        \r\n",
        "        output = net(test_vector)\r\n",
        "        prediction = torch.sigmoid(output).item()\r\n",
        "\r\n",
        "        if prediction > 0.5:\r\n",
        "            print(f'{prediction:0.3}: Positive sentiment')\r\n",
        "        else:\r\n",
        "            print(f'{prediction:0.3}: Negative sentiment')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbCc5HhJ2zW4",
        "outputId": "292b7ebc-643c-4872-cf0c-f0ae9828b9e2"
      },
      "source": [
        "test_text = '''\r\n",
        "Really good I like him as he was the main character who fight with Voldemort very greatly. I m an asian and India it so popular and I wish to meet u three\r\n",
        "Ur performance and that quidditch match was so excited and also that ghost who guards that jail\r\n",
        "And also serious black \r\n",
        "I also wish that producer has to make more films of them show dumbuledore, harmony, Ronald, serious black, Voldemort, Mrs. Weasley, Malfoy, and also HARRY POTTER.\r\n",
        "💝💝💖💖💖💖\r\n",
        "In ur first part that kingdom and that style you came here and the post letter that has been giving in your home again and again by an owl and that magic when haegret make that magical by giving tale that was so interesting and also that u r famous for ur that sign when Voldemort kill ur parent but u saved and Voldemort gave u some power of him that was very scared and shocking that Voldemort a simple boy who taught by dumbledore bitten him easily and I couldn't understand why another school helps them?\r\n",
        "please give a reply to my question \r\n",
        "I m your big fan. I saw ur picture again and again\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "I REQUEST TO FORWARD THIS MESSAGE TO EMMA WATSON, RUPERT GRINT, AND DANIEL REDCLIFFE \r\n",
        "'''\r\n",
        "\r\n",
        "predict_sentiment(test_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.604: Positive sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ve_h3jc3GoS",
        "outputId": "b8a37642-6373-4fdb-d5d4-d90d9753ce74"
      },
      "source": [
        "test_text = '''\r\n",
        "I'm going to write the honest and sincere comments and suggestions for indian audiance who watch most bollywood films. \r\n",
        "Guys first of all the entire Race Frenchie that is race 1, and 2 both are ripped off from Hollywood flick check out in Google and IMBD that means they are entirely copy pasted the movie even the songs composed by copycat Pritam Chakraborty. Song's we're copied from Korean album my Sasi girl. \r\n",
        "Now Race 3 what is new .... Nothing 😂 there is nothing in this movie which makes you heartwarming, eye catching or any sort of connection with characters in the movie. This movie is also not worth watching for free on television because your valuable time will be wasted and that is equal to loosing MONEY. \r\n",
        "When this movie got first premiered on television on I suppose on Zee cinema. I watched this for nearly 10 minutes and I felt what the heck I'm doing during break i just browsing through channels I came across Hollywood Bean movie. This movie really saved my day and got rid of Race 3. \r\n",
        "Why people are still praising salman khan why he's now getting aged and he should pass on the battle and let New face come to bollywood but unfortunately it's bollywood Full of nepotism it will never improve it's nepotism, favouritism strategy. Hence request you All please don't waste your time and money on these worthless star's. \r\n",
        "There are wonderful... Incredible astonishing amazing Hollywood flicks collection you can watch instead of this kind of trash\r\n",
        "'''\r\n",
        "\r\n",
        "predict_sentiment(test_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0316: Negative sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDmPXD1h4L78"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}